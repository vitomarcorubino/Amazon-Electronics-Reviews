{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reading dataset",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T14:54:09.840409500Z",
     "start_time": "2026-01-28T14:54:09.770406500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import gzip"
   ],
   "id": "fbc121e30a2defb3",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T09:53:41.974527Z",
     "start_time": "2026-01-28T09:53:41.964739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definiamo il contesto per tradurre i termini JSON in Python\n",
    "# Questo dice a eval(): \"Se trovi 'true', intendi True\", ecc.\n",
    "safe_context = {\n",
    "    \"true\": True,\n",
    "    \"false\": False,\n",
    "    \"null\": None,\n",
    "    \"nan\": float('nan') # A volte capita anche questo\n",
    "}"
   ],
   "id": "14a430415377c177",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T09:54:29.969719Z",
     "start_time": "2026-01-28T09:54:29.963362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse(file_path):\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as gzip_file:\n",
    "        for line in gzip_file:\n",
    "            try:\n",
    "                # Passiamo 'safe_context' come secondo argomento a eval\n",
    "                # In questo modo 'true' viene letto correttamente come True\n",
    "                yield json.dumps(eval(line, safe_context))\n",
    "            except Exception as e:\n",
    "                # Stampiamo l'errore specifico per capire se ci sono altri problemi\n",
    "                # Ma non interrompiamo tutto\n",
    "                # print(f\"Skipping line due to: {e}\")\n",
    "                continue"
   ],
   "id": "2668982cf1f50909",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T09:54:34.514421Z",
     "start_time": "2026-01-28T09:54:34.499604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_dataset(input_filename, output_filename):\n",
    "    print(f\"Starting conversion: {input_filename} -> {output_filename}...\")\n",
    "\n",
    "    # Open the output file for writing\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f_out:\n",
    "        # Iterate through the generator\n",
    "        for i, json_line in enumerate(parse(input_filename)):\n",
    "            f_out.write(json_line + '\\n')\n",
    "\n",
    "            # Print progress every 100,000 lines so you know it's working\n",
    "            if (i + 1) % 1000000 == 0:\n",
    "                print(f\"Processed {i + 1} records...\")\n",
    "\n",
    "    print(f\"Done! Saved to {output_filename}\")"
   ],
   "id": "183f687eee7a313d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T10:16:49.578717Z",
     "start_time": "2026-01-28T09:54:37.059873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "convert_dataset(input_filename = \"data/Electronics.json.gz\",\n",
    "                output_filename = \"data/reviews_electronics.json\")"
   ],
   "id": "84f1105d40ff8e48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversion: data/Electronics.json.gz -> data/reviews_electronics.json...\n",
      "Processed 1000000 records...\n",
      "Processed 2000000 records...\n",
      "Processed 3000000 records...\n",
      "Processed 4000000 records...\n",
      "Processed 5000000 records...\n",
      "Processed 6000000 records...\n",
      "Processed 7000000 records...\n",
      "Processed 8000000 records...\n",
      "Processed 9000000 records...\n",
      "Processed 10000000 records...\n",
      "Processed 11000000 records...\n",
      "Processed 12000000 records...\n",
      "Processed 13000000 records...\n",
      "Processed 14000000 records...\n",
      "Processed 15000000 records...\n",
      "Processed 16000000 records...\n",
      "Processed 17000000 records...\n",
      "Processed 18000000 records...\n",
      "Processed 19000000 records...\n",
      "Processed 20000000 records...\n",
      "Done! Saved to data/reviews_electronics.json\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T10:21:34.325407Z",
     "start_time": "2026-01-28T10:16:49.690741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "convert_dataset(input_filename = \"data/meta_Electronics.json.gz\",\n",
    "                output_filename = \"data/metadata_electronics.json\")"
   ],
   "id": "fcb9a2f0121f08af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversion: data/meta_Electronics.json.gz -> data/metadata_electronics.json...\n",
      "Done! Saved to data/metadata_electronics.json\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
